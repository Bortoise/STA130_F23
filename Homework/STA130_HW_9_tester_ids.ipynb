{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Coding Homework 9: [put your name here]\n",
    "\n",
    "Go through this notebook, following the instructions! (Remember to not delete or create any cells)\n",
    "\n",
    "> TAs will mark this assignment by checking ***MarkUs*** autotests and by manually grading Q12.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We begin by importing dataset and the libraries we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree, model_selection\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import graphviz as gv\n",
    "happiness2017 = pd.read_csv(\"happiness2017.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Gallup Report Happiness Survey\n",
    "Using data from the Gallup World Poll (and the World Happiness Report), we are interested in predicting which factors influence life expectancy around the world. These data are in the file happinessdata_2017.csv, which we imported as `happiness2017`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Q1: Add a new column to `happiness2017` called `life_exp_good` which is `True` for countries with life expectancy higher than 65 years, and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: your answer will be tested!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  sum(happiness2017.life_exp_good == True) == 573\n",
    "hint = \"Use .head() to see the existing columns and then use a boolean condition to define your new column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q1\n",
    "assert test, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Now divide create a new dataframe `happiness2017_cleaned` from `happiness2017` that contains the following columns `life_exp_good`, `logGDP`, `social_support`, `freedom`, and `generosity`, with all rows with `NaN` entries dropped. Then create an 80/20 split (80% training set and 20% testing set) for the `happiness2017_cleaned` data.\n",
    "\n",
    "- To do this in a reproducible way, we're going to set a \"random seed\"; and, in preparation for this, let's take a moment to motivate our choice of $1985$ for the \"random seed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "# 19, 19, 1985!\n",
    "YouTubeVideo('K38xNqZvBJI', width=800, height=500)\n",
    "# Remember, always choose your favorite number for your \"random seeds\"\n",
    "# The specific number you choose doesn't even really matter, which is why \n",
    "# it's so important to make a big deal about it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Data_Split",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) # do NOT change this line: it sets the \"random number generation seed\"\n",
    "# which makes the \"pseudorandomness\" gererated in the code the same every time and this\n",
    "# makes the code reproducibile which ensures that our testing code works properly every time\n",
    "happiness2017_cleaned = None\n",
    "train, test = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Q2: Train a classification tree `clf` using only the  `social_support` variable to predict if a country has good life expectancy\n",
    "\n",
    "#### Use default values for all (tuning) parameters instantiating the Decision Tree Classifier.\n",
    "\n",
    "> Hint: should you use the `train` data, or the `test` data, or all this data combined to fit the classification tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: your answer will be tested!\n",
    "np.random.seed(1985) #Do not change this line\n",
    "clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q2_preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = test[[\"life_exp_good\", \"social_support\"]].dropna()\n",
    "Xt = testdata.iloc[:,1:]\n",
    "Yt = testdata.life_exp_good\n",
    "\n",
    "test = sum(Yt == clf.predict(Xt)) == 250\n",
    "hint = \"Make sure to train on just the training dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q2\n",
    "assert test, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Now you can visualize your tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tree.plot_tree(clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Or to make it look prettier we can use graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=[\"social_support\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "And to make it legible we can add the max_depth parameter to our call of export_graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, max_depth=3,\n",
    "                                feature_names=[\"social_support\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Q3: How many observation are in the training data set and the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q3_empty_cell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: your answer will be tested!\n",
    "num_train = None # Replace this with the number of observations in the training set\n",
    "num_test = None # Replace this with the number of observations in the test set\n",
    "Q3 = (num_train, num_test) # Do not change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Q3 == (999,250)\n",
    "hint = \"Use google if you need help figuring out how to use `clf.predict()`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q3\n",
    "assert test, hint "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Q4: Why did you fit the classification tree with the data set you did?\n",
    "\n",
    "#### Write a one to two sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"The training data set was used in order to save some test data which allows us to see how the model predicts on new data that it hasn't seen before and hasn't used to fit itself.  If we see how a model performs using data that it has had the chance to see and learn (and even potentially sort of memorize?) then we'll have a false sense of confidence in the capabilites of the model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q4\n",
    "assert False, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Q5: Comment on the complexity of the decision tree classification model visualized above, especially in light of the fact that only a single feature was used to predict the outcome in this model.\n",
    "\n",
    "\n",
    "#### Write a one to two sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "> Answer here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"This decision tree seems like a really complex model with all sorts of branches as rules for making the prediction of good life expetancy based on just the single `social_support` variable. Since the `social_support` variable is a continuous numerical value, this means that predictions are being made based on very specific interval ranges of the values of this variable, which is highly suggestive of a very particular and specific model that could be at risk of overfitting to the specific idiosynchrosies of the given data set.  The training data set include 1038 observations; so, perhaps this might be enough to justify the complexity of the constructed decision tree; but, the way we could see if this was the case would be by seeing how the fitted decision tree performs on new data. I.e., can it generalize to new data that wasn't used in its construction? That would be very telling about how overfit it was to the idiosynchrosies of the data set used to fit it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q5\n",
    "assert False, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Q6: Use the `clf.predict()` method to answer the following questions and confirm your answer using the `graphviz` visualization of the decision tree\n",
    "a) Does your decision tree predict that a country with `social_support = .70` has good life expectancy?  \n",
    "b) what if `social_support = .71`  \n",
    "c) what if `social_support = .72`  \n",
    "d) what if `social_support = .9`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: your answer will be tested!\n",
    "Q6a = None # Replace this with True or False: don't supply something like array([False])\n",
    "Q6b = None\n",
    "Q6c = None\n",
    "Q6d = None\n",
    "Q6 = (Q6a, Q6b, Q6c, Q6d) # Do not change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Q6 == (False, True, False, True)\n",
    "hint = \"Try google if you need help figuring out how to use `clf.predict()`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q6\n",
    "assert test, hint "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Do these predictions make sense to you?\n",
    "\n",
    "Look at how these small differences in the input rapidly change the predicted label... it seems kind of strange. It's a little hard to intuitively see why predictions should change like this... it makes you wonder if the model is really doing anything meaningful here.  \n",
    "\n",
    "Perhaps the model might just actually be overly complex and convoluted and might be overinterpreting the data used to fit it (which we call overfitting). Since you'll probably agree that the behaviour of the model that we're observing seems a bit off, you'll probably also agree that it's a reasonable idea to try reduce the complexity of the model so it can be more reliably estimated with the data at hand.  With that in mind, create and fit a new classification tree `clf2` on the same inputs with a maximum depth of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clf2_creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) #Do not change this line\n",
    "clf2 = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Q7: Reanswer Q6 with `clf2`.\n",
    "\n",
    "#### Use the same train/test split data used so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: your answer will be tested!\n",
    "Q7a = None # Replace this with True or False\n",
    "Q7b = None\n",
    "Q7c = None\n",
    "Q7d = None\n",
    "Q7 = (Q7a, Q7b, Q7c, Q7d) # Do not change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q7_prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"Use google to figure out how to use `clf.predict()`\\n\"\n",
    "hint += \"but feel free to just figure out the class labels in the decision tree\\n\"\n",
    "hint += \"visualizations and then you can just read the answers of the from plot.\"\n",
    "test = Q7 == (False, False, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q7\n",
    "assert test, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Now train another classification tree `clf3` using `logGDP`, `social_support`, `freedom`, and `generosity` as potential predictors.\n",
    "\n",
    "#### Use the same train/test split data used so far and use default (tuning) parameters when instantiating the model (so, e.g., don't set a maximum tree depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clf3_creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1985) #Do not change this line\n",
    "clf3 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf3, out_file=None, max_depth= 3,\n",
    "                                feature_names=[\"logGDP\", \"social_support\", \"freedom\", \"generosity\"],\n",
    "                                class_names=[\"Good\", \"Bad\"],\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = gv.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Q8: Use the testing dataset you created in Q1 to create confusion matrices for `clf2` and `clf3`. Report the sensitivity (true positive rate), specificity (true negative rate) and accuracy for each of the trees/models.\n",
    "\n",
    "\n",
    "#### Provide your answers as decimal numbers with three signifiant digits, such as `0.123` (and not as percentages like `12.3%`), and treat “Good” life expectancy as the positive response and prediction class. \n",
    "\n",
    "> Hint 1: Use `np.round(0.1234,3)` to produce the correct rouding for the answers  \n",
    "> Hint 2: `y_true` or `y_pred` parameter go first in the `confusion_matrix` function?  \n",
    "> Hint 3: Which columns/features of the `test` data set should be used for `clf2` versus `clf3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8_empty_cell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: your answer will be tested!\n",
    "(clf2_sensitivity, clf2_specificity, clf2_accuracy) = (None, None, None) #Replace the Nones with the corresponding answers\n",
    "(clf3_sensitivity, clf3_specificity, clf3_accuracy) = (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata1 = test[[\"life_exp_good\", \"social_support\"]]\n",
    "testdata2 = test[[\"life_exp_good\", \"logGDP\", \"social_support\", \"freedom\", \"generosity\"]]\n",
    "CM2 = confusion_matrix(testdata1.life_exp_good, clf2.predict(testdata1.iloc[:,1:]))\n",
    "CM3 = confusion_matrix(testdata2.life_exp_good, clf3.predict(testdata2.iloc[:,1:]))\n",
    "\n",
    "sens2 = CM2[1][1]/sum(CM2)[1]\n",
    "spec2 = CM2[0][0]/sum(CM2)[0]\n",
    "acc2 = (CM2[0][0]+CM2[1][1])/sum(sum(CM2))\n",
    "\n",
    "sens3 = CM3[1][1]/sum(CM3)[1]\n",
    "spec3 = CM3[0][0]/sum(CM3)[0]\n",
    "acc3 = (CM3[0][0]+CM3[1][1])/sum(sum(CM3))\n",
    "\n",
    "test = (clf2_sensitivity, clf2_specificity, clf2_accuracy, clf3_sensitivity, clf3_specificity, clf3_accuracy) == \\\n",
    "       (sens2,             spec2,           acc2,         sens3,             spec3,             acc3)\n",
    "hint = \"Make sure you rounded up, and didn't confuse what the rows and columns of the confusion matrix mean. ConfusionMatrixDisplay.from_predictions might help with this.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q8\n",
    "assert test, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "As we are statisticians in this course, the extent to which we do not understand the internal workings and predictions from our decision trees depend on the predictor variables should feel a bit off-putting. To remedy this we can use heuristics to judge how relatively important the different predictor variables are. For our purposes the simplest heuristic we can use is the Gini Importance: the gini importance of a predicting variable X is defined as the number of nodes which split on X divided by the total number of splits in the tree.  You can find the gini importances from a classification tree using `.feature_importances_`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Q9: Which predictor variable is most important for making predictions according to clf3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9_empty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: your answer will be tested!\n",
    "Q9 = None # Replace this with the name of the most relevant predictor variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Q9 == \"logGDP\"\n",
    "hint = \"You can read off the feature_importances and answer with the more important feature.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q9\n",
    "assert test, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Q10: Describe the differences/similarities of interpreting coefficients in linear model regression versus feature importances in decision trees.\n",
    "#### Write a 1-2 sentence answer to this question in markdown cell below\n",
    "- Compare your response to the answer given in the ***MarkUs*** output.\n",
    "\n",
    "Hint: Consider the differing goals of linear regression and classification trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint +=  \"Regression coefficients represent mean responses of the predicted value as the predictor variables vary but feature importances in decision trees just represent which features were more relevant in constructing the decision tree. As such, regression coefficients can be interpreted directly in terms of the scenario and can be readily compared across models, whereas feature importances can not be directly interpreted and only provide a relative ranking of relevance.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q10\n",
    "assert False, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# Confusion matrices and Metrics\n",
    "Accuracy is the proportion of cases that are correctly identified.\n",
    "Sensitivity, also known as true positive rate (TPR), is the proportion of actual positive cases which are correctly identified to be positive (i.e. are true positives).\n",
    "Specificity, also known as true negative rate (TNR), is the proportion of actual negative cases which are correctly identified to be negative (i.e. are true negative).\n",
    "False positive/negative rates are defined to be the proportion of actual positive/negative cases which are incorrectly identified.\n",
    "In formulas,\n",
    "$$ Accuracy = (TP+TN)/\\text{total \\# of cases}$$\n",
    "$$ TPR = TP/(TP+FN) = 1-FNR$$\n",
    "$$ TNR = TN/(TN+FP) = 1-FPR$$\n",
    "You can read more and see a handy list of formulas at the following [wikipedia page.](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Two classification trees were built to predict which individuals have a disease using different sets of potential predictors. We use each of these trees to predict disease status for 100 new individuals. Below are confusion matrices corresponding to these two classification trees. The columns are the actual outcome, the rows are predicted outcomes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| **Tree A**         | Disease | No disease | $\\hspace{1in}$ | **Tree B**         | Disease | No disease |\n",
    "|--------------------|---------|------------|----------------|--------------------|---------|------------|\n",
    "| Predict disease    | 36      | 22         |                | Predict disease    | 24      | 6          |\n",
    "| Predict no disease | 2       | 40         |                | Predict no disease | 14      | 56         |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Q11: Calculate the accuracy, false-positive rate, and false negative rate for each classification tree.\n",
    "Here, a “positive” result means we predict an individual has the disease and a “negative” result means we predict they do not.\n",
    "Round each value to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11: your answer will be tested!\n",
    "TreeA_accuracy = None\n",
    "TreeA_false_positive_rate = None\n",
    "TreeA_false_negative_rate = None\n",
    "\n",
    "TreeB_accuracy = None\n",
    "TreeB_false_positive_rate = None\n",
    "TreeB_false_negative_rate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (TreeA_accuracy, TreeA_false_positive_rate, TreeA_false_negative_rate, TreeB_accuracy, TreeB_false_positive_rate, TreeB_false_negative_rate) == (.76,.35,.05,.80,.10,.37)\n",
    "hint = \"Make sure you round correctly and calculate the FALSE positive and negative rates.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q11\n",
    "assert test, hint "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Q12: Which tree would you prefer to put into use in predicting if individuals are ill?\n",
    "#### Write a 1-3 sentence answer to this question in markdown cell below.\n",
    "- This question will be manually graded by TAs. They are **not** looking for a specific answer, any well written answer is acceptable.\n",
    "- You can see the **MarkUs** output for some ideas.\n",
    "\n",
    "Hint 1: Make reference to the metrics you calculated in Q10, and any others you think might matter.\n",
    "Hint 2: Interpret what the metrics mean in the context of the problem before deciding how much the metrics matter to you.\n",
    "Hint 3: What tradeoffs might you find acceptable vs. unacceptable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "> Answer here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q12_empty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "hint = \"\\n\\nAUTOMATICALLY FAILING AUTOTEST: DOES NOT COUNT AGAINST STUDENT\\n\"\n",
    "hint += \"Included as an example answer for feedback purposes only\\n\\n\"\n",
    "hint += \"You might prefer tree A to tree B because it has a lower false negative ratio, meaning that more people who need treatment will get it. Alternatively you could argue that tree B is better because it has a higher overall accuracy and depending on the disease, a false positive might be more damaging than a false negative.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q12\n",
    "assert False, hint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Geometric Interpretation of Prediction\n",
    "Data was collected on 30 cancer patients to investigate the effectiveness (Yes/No) of a treatment. Two quantitative variables x1 and x2 (taking values between 0 and 1) are thought to be important predictors of effectiveness. Suppose that the rectangles labeled as nodes in the scatter plot below represent nodes of a classification tree.\n",
    "![Scatter plot with a horizontal x1 axis and vertical x2 axis, both ranging from 0.00 to 1.00, and blue triangular points representing Effectiveness = 'Yes' and round orange points representing Effectiveness = 'No'. It is divided into 4 regions, labelled nodes 1-4. Node 1 is the bottom left region, node 4 the bottom right, node 3 the top left, and node 2 the top right. The top regions are divided from the bottom ones by a horizontal line along x_2=0.50. Node 2 is separated from node 3 by a line at x1=0.50. Node 2 is separated from node 3 by a line at x1=0.50. Node 1 has 5 'Yes' nodes and 7 'No' Nodes. Node 2 has 3 'Yes' nodes and 2 'No' Nodes. Node 3 has 1 'Yes' node and 3 'No' Nodes. Node 4 has 2 'Yes' nodes and 7 'No' Nodes.](HW9_Q7_Graph.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "### Q13: The diagram above is the geometric interpretation of a classification tree to predict drug effectiveness based on two predictors, x1 and x2. What is the predicted class of each node?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13: your answer will be tested!\n",
    "Q13_Node1 = None #Replace with 'Yes' or 'No'\n",
    "Q13_Node2 = None\n",
    "Q13_Node3 = None\n",
    "Q13_Node4 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (Q13_Node1, Q13_Node2, Q13_Node3, Q13_Node4) == ('No', 'Yes', 'No', 'No')\n",
    "hint = \"Hint: The classification tree will pick 'Yes' or 'No' for each region depending on which is more common in that region.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q13\n",
    "assert test, hint "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Q14: What is the first variable that the decision tree splits on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14: your answer will be tested!\n",
    "Q14 = None # Replace with 'x1' or 'x2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Q14 == 'x2'\n",
    "hint = \"Recall the lines in the diagram correspond to splits in the decision tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_Q14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Q14\n",
    "assert test, hint "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
